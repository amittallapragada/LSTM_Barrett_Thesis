{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UEUC_SKZZpd3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating Lyrics with LSTM Networks\n"
      ]
    },
    {
      "metadata": {
        "id": "tvuMsNqEWd12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5311664-909f-4dcf-9407-0ace6e22311a"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, CuDNNLSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping,LambdaCallback\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "#note make sure to change your runtime hardware accelerator to include a GPU\n",
        "device_name = tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RxHtkYW-Z5Ll",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To access files on Colab, you can import data directly to your google drive account and access it from there"
      ]
    },
    {
      "metadata": {
        "id": "0IyQdK1zWuit",
        "colab_type": "code",
        "outputId": "9a92ea4c-2ae0-48bd-8f7b-147043c05391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dqgngaqzaBeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "\n",
        "1.   Get a dataset of a particular artist's songs\n",
        "2.   Create one string of all the songs\n",
        "3.   Chunk this string into n-word sequences having the next word in the string be a sequence's target variable (explained clearer in paper)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YT4_i4GfWd16",
        "colab_type": "code",
        "outputId": "6dcc4a7e-852f-4a80-a960-a23aaa3c22ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('PATH_TO_DATA/taylor_swift.csv')\n",
        "data.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Name</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tim mcgraw</td>\n",
              "      <td>\\n\\r\\nhe said the way my blue eyes shined\\nput...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>picture to burn</td>\n",
              "      <td>\\n\\r\\nstate the obvious, i didn't get my perfe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>teardrops on my guitar</td>\n",
              "      <td>\\n\\r\\ndrew looks at me.\\ni fake a smile so he ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a place in this world</td>\n",
              "      <td>\\n\\r\\ni don't know what i want, so don't ask m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>cold as you</td>\n",
              "      <td>\\n\\r\\nyou have a way of coming easily to me\\na...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                    Name  \\\n",
              "0           0              tim mcgraw   \n",
              "1           1         picture to burn   \n",
              "2           2  teardrops on my guitar   \n",
              "3           3   a place in this world   \n",
              "4           4             cold as you   \n",
              "\n",
              "                                              Lyrics  \n",
              "0  \\n\\r\\nhe said the way my blue eyes shined\\nput...  \n",
              "1  \\n\\r\\nstate the obvious, i didn't get my perfe...  \n",
              "2  \\n\\r\\ndrew looks at me.\\ni fake a smile so he ...  \n",
              "3  \\n\\r\\ni don't know what i want, so don't ask m...  \n",
              "4  \\n\\r\\nyou have a way of coming easily to me\\na...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "4ZARPWf0Wd1-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Make 1 string with all files"
      ]
    },
    {
      "metadata": {
        "id": "VcPruZnYWd1_",
        "colab_type": "code",
        "outputId": "30d3b24b-af6d-4f19-98a9-f1cb4135d9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "test = []\n",
        "for song in data.Lyrics:\n",
        "    text = text + song\n",
        "    test.append(song.split(' '))\n",
        "\n",
        "print('average taylor swift song length')\n",
        "x = [len(t) for t in test]\n",
        "sum(x) / len(x)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average taylor swift song length\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307.14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "kLR11rAKWd2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare Dataset\n",
        "-chunk data into sequences"
      ]
    },
    {
      "metadata": {
        "id": "3R3qJGxVWd2D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "def data_prep(data):\n",
        "    text = data.lower().split('\\n')\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    #convert our list of split words into sequences\n",
        "    sequences = []\n",
        "    for line in text:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram = token_list[:i+1]\n",
        "            sequences.append(n_gram)\n",
        "    #find the longest sequences length so we can pad the others to that len\n",
        "    max_len = max([len(x) for x in sequences])\n",
        "    #we add our paddings to the beginning of each val\n",
        "    sequences = np.array(pad_sequences(sequences, maxlen=max_len, padding='pre'))\n",
        "    print(sequences.shape)\n",
        "    X, y = sequences[:,:-1], sequences[:,-1]\n",
        "    y = ku.to_categorical(y, num_classes=total_words)\n",
        "    return X, y, total_words, max_len\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfxt_jQcWd2F",
        "colab_type": "code",
        "outputId": "95ecd80f-49e0-4e38-8d98-fb1b058eced7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X,y,total_words,max_len = data_prep(text)\n",
        "max_len\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30729, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SEwZUImAWd2I",
        "colab_type": "code",
        "outputId": "c5d809d7-5fed-4def-9594-669e831e3717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(X[1].shape)\n",
        "print(max_len)\n",
        "print(total_words)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30729, 24)\n",
            "(24,)\n",
            "25\n",
            "2446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m1JsFr7va4HX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build our Model"
      ]
    },
    {
      "metadata": {
        "id": "s5n4A8t2bmyK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## We build a 1 Layer LSTM Model W/an Embedding and Dropout Layer (hyperparameter justifications are in our paper)\n",
        "- Through testing we found that adam was the best optimizer for text generation\n",
        "- We used categorical crossentropy for loss as this was a multi-class classification problem. The network has a dense output layer with n-nodes where n represents all the unique words in our corpus."
      ]
    },
    {
      "metadata": {
        "id": "J_1fAMIaWd2L",
        "colab_type": "code",
        "outputId": "23f3f44e-55c0-43b3-9890-e4277509dded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 50, input_length=max_len-1))\n",
        "model.add(CuDNNLSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 24, 50)            122300    \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               92160     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2446)              315534    \n",
            "=================================================================\n",
            "Total params: 529,994\n",
            "Trainable params: 529,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SSDmpocCcIXa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We chose to run our network for 200 epochs "
      ]
    },
    {
      "metadata": {
        "id": "29hKSZgdZgty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=200, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vp5jM5IbcN3b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pretrained model can be found on GitHub"
      ]
    },
    {
      "metadata": {
        "id": "6B6M9OiJ0A2W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('PATH_TO_DATA/data/final_tswift_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_AaEMOslcSNV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating text with our model"
      ]
    },
    {
      "metadata": {
        "id": "Rx6r56NTWd2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(epoch, logs):\n",
        "    num_of_words_to_gen = 50\n",
        "    seed_text = \"those georgia stars\"\n",
        "    if epoch % 10 == 0:\n",
        "      print('----- Generating text after Epoch: %d' % epoch)\n",
        "      \n",
        "      for j in range(num_of_words_to_gen):\n",
        "          #format token as a model input\n",
        "          seed_token = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "          seed_token = pad_sequences([seed_token], maxlen=max_len-1, padding='pre')\n",
        "          #predict\n",
        "          predicted = model.predict_classes(seed_token, verbose=0)\n",
        "          output_word = \"\"\n",
        "          for word, index in tokenizer.word_index.items():\n",
        "              if index == predicted:\n",
        "                  output_word = word\n",
        "                  break\n",
        "          seed_text += \" \" + output_word\n",
        "      print(seed_text)\n",
        "      print('\\n')\n",
        "\n",
        "generate_text = LambdaCallback(on_epoch_end=generate_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5uWVDQ9Og9B_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "ind_to_word = dict((v,k) for k,v in tokenizer.word_index.items())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZsYdfZbiWd2T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, num_of_words_to_gen):\n",
        "#     num_of_words_to_gen = 14144\n",
        "    #num_of_words_to_gen = 10\n",
        "    for j in range(num_of_words_to_gen):\n",
        "        #format token as a model input\n",
        "        seed_token = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        seed_token = pad_sequences([seed_token], maxlen=max_len-1, padding='pre')\n",
        "        #predict\n",
        "        predicted = model.predict_classes(seed_token, verbose=0)\n",
        "        output_word = ind_to_word[predicted[0]]\n",
        "#         for word, index in tokenizer.word_index.items():\n",
        "#             if index == predicted:\n",
        "#                 output_word = word\n",
        "#                 break\n",
        "        seed_text = seed_text + \" \" + output_word\n",
        "    print('\\n')\n",
        "    return seed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a4IRz2w4Wd2W",
        "colab_type": "code",
        "outputId": "325428eb-e7a2-4ebd-db6a-f2c6b9bdd6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "generate_text('those georgia stars to shame that night', 200)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"those georgia stars to shame that night you need to feel like i like you and i didn't wonder you i loved you down to listen to you but 'bout you feel come to light right now christmas love you alone for me yeah yeah yeah yeah yeah yeah yeah i i i i i i i i i i i begging you fragile i was only everything i have to long gone i bring you now finally breathe at you met you like right like why all i feel it all right now same things happen when you were into right through all right all in time is a drawer we’d knowing rains in the team around now we need you’ but i'm pacing back up for the back of us i where tim incredible \\r you and right in this room at night lives right here snow radio wouldn't wanna' back door for us to be small old bitter anymore onto trees dreaming tried cheer memories come back turning every asking trust you've killing me to be sorry the time for you said \\r and you hope me why ain't right here me year i'm mad is you feel the one day to the whole\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}