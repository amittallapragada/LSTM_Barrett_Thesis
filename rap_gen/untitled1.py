# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vyd7VWnAzBqU1pJb3545kvd4CRVW9gBa
"""

import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import LSTM
from keras.callbacks import ModelCheckpoint
from keras.utils import np_utils
from keras.models import load_model
df = pd.read_excel('kanye_lyrics.xlsx')

lyrics = df.Lyrics

text = lyrics[1]
text = text.split()
new_text = []
for i in range(len(text)):
  test = text[i]
  if test.isdigit() == False:
    new_text.append(test)
  # if text[i].isdigit() == True:
  #   del text[i]
text = " ".join(new_text)
text = text.lower()
print(text)

chars = sorted(list(set(text)))
char_to_int = dict((c, i) for i, c in enumerate(chars))
n_chars = len(text)
n_vocab = len(chars)
print("Total Characters: ", n_chars)
print("Total Vocab: ", n_vocab)

seq_length = 10
dataX = []
dataY = []
count = 0
for i in range(0, n_chars - seq_length, 1):
  seq_in = text[i:i + seq_length]
  seq_out = text[i + seq_length]
  dataX.append([char_to_int[char] for char in seq_in])
  dataY.append(char_to_int[seq_out])
  count+= 1
n_patterns = len(dataX)
print("Total Patterns: ", n_patterns)

# reshape X to be [samples, time steps, features]
X = np.reshape(dataX, (n_patterns, seq_length, 1))
# normalize
#X = X / float(n_vocab)
# one hot encode the output variablerd etu;'

y = np_utils.to_categorical(dataY)

# define model
model = Sequential()
model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))
model.add(Dense(n_vocab, activation='softmax'))
print(model.summary())

# compile model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit model
#model.fit(X, y, epochs=30, verbose=2)
#model.save('test_model_amit2.h5')

model = load_model('test_model_amit2.h5')

int_to_char = {v: k for k, v in char_to_int.items()}
print(int_to_char)
# pick a random seed
start = 1
print(start)
pattern = dataX[start]
print(pattern)
print("Seed:")
print("\"", ''.join([int_to_char[value] for value in pattern]), "\"")
print('end seed')
output = ""
for i in range(100):
    x = np.reshape(pattern, (1, len(pattern), 1))
    x = x / float(n_vocab)
    prediction = model.predict(x, verbose=0)
    index = np.argmax(prediction)
    print(prediction)
    result = int_to_char[index]
    seq_in = [int_to_char[value] for value in pattern]
    output = output + result
    pattern.append(index)
    pattern = pattern[1:len(pattern)]
print(output)
print("\nDone.")

