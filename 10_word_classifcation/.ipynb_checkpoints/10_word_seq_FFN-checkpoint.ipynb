{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import np_utils\n",
    "#sklearn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x129ce3128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_pickle('10_word_seqs.pkl', compression='gzip')\n",
    "print(len(df))\n",
    "sns.countplot(df.genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess data\n",
    "-  make our 10 word sequences integer encoded\n",
    "- use one-hot encoding to encode our genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating our feature set w/Keras tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 3, 3],\n",
       "       [0, 0, 0, ..., 4, 1, 7],\n",
       "       [0, 0, 0, ..., 2, 4, 2],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 4, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#this value is the length of the longest song in our dataset.\n",
    "MAX_VALUE = 10 #the length of each of our sequences\n",
    "tok = Tokenizer(num_words=MAX_VALUE)\n",
    "tok.fit_on_texts(df.lyrics)\n",
    "#build sequences\n",
    "sequences = tok.texts_to_sequences(df.lyrics)\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen=MAX_VALUE)\n",
    "sequences_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating our target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(df.genre)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split into test/train 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(sequences_matrix,onehot_encoded,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=X_train[0].shape, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30589 samples, validate on 7648 samples\n",
      "Epoch 1/100\n",
      "30589/30589 [==============================] - 0s 13us/step - loss: 1.3882 - acc: 0.2731 - val_loss: 1.3820 - val_acc: 0.2891\n",
      "Epoch 2/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3792 - acc: 0.2907 - val_loss: 1.3769 - val_acc: 0.2926\n",
      "Epoch 3/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3757 - acc: 0.2913 - val_loss: 1.3760 - val_acc: 0.2862\n",
      "Epoch 4/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3725 - acc: 0.2968 - val_loss: 1.3732 - val_acc: 0.2924\n",
      "Epoch 5/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3706 - acc: 0.2958 - val_loss: 1.3683 - val_acc: 0.3001\n",
      "Epoch 6/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3685 - acc: 0.2988 - val_loss: 1.3662 - val_acc: 0.2984\n",
      "Epoch 7/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3668 - acc: 0.3006 - val_loss: 1.3639 - val_acc: 0.3037\n",
      "Epoch 8/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3658 - acc: 0.3047 - val_loss: 1.3712 - val_acc: 0.3001\n",
      "Epoch 9/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3645 - acc: 0.3033 - val_loss: 1.3654 - val_acc: 0.3033\n",
      "Epoch 10/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3633 - acc: 0.3068 - val_loss: 1.3628 - val_acc: 0.3019\n",
      "Epoch 11/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3616 - acc: 0.3098 - val_loss: 1.3613 - val_acc: 0.3022\n",
      "Epoch 12/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3616 - acc: 0.3105 - val_loss: 1.3604 - val_acc: 0.3145\n",
      "Epoch 13/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3606 - acc: 0.3114 - val_loss: 1.3640 - val_acc: 0.3142\n",
      "Epoch 14/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3597 - acc: 0.3129 - val_loss: 1.3624 - val_acc: 0.3146\n",
      "Epoch 15/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3591 - acc: 0.3119 - val_loss: 1.3609 - val_acc: 0.3236\n",
      "Epoch 16/100\n",
      "30589/30589 [==============================] - 0s 16us/step - loss: 1.3582 - acc: 0.3176 - val_loss: 1.3621 - val_acc: 0.3230\n",
      "Epoch 17/100\n",
      "30589/30589 [==============================] - 0s 14us/step - loss: 1.3583 - acc: 0.3151 - val_loss: 1.3604 - val_acc: 0.3150\n",
      "Epoch 18/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3584 - acc: 0.3149 - val_loss: 1.3576 - val_acc: 0.3251\n",
      "Epoch 19/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3569 - acc: 0.3183 - val_loss: 1.3570 - val_acc: 0.3260\n",
      "Epoch 20/100\n",
      "30589/30589 [==============================] - 0s 13us/step - loss: 1.3572 - acc: 0.3149 - val_loss: 1.3570 - val_acc: 0.3223\n",
      "Epoch 21/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3566 - acc: 0.3188 - val_loss: 1.3556 - val_acc: 0.3283\n",
      "Epoch 22/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3561 - acc: 0.3200 - val_loss: 1.3600 - val_acc: 0.3224\n",
      "Epoch 23/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3559 - acc: 0.3207 - val_loss: 1.3574 - val_acc: 0.3185\n",
      "Epoch 24/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3556 - acc: 0.3179 - val_loss: 1.3558 - val_acc: 0.3264\n",
      "Epoch 25/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3550 - acc: 0.3186 - val_loss: 1.3586 - val_acc: 0.3135\n",
      "Epoch 26/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3548 - acc: 0.3221 - val_loss: 1.3581 - val_acc: 0.3256\n",
      "Epoch 27/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3544 - acc: 0.3203 - val_loss: 1.3574 - val_acc: 0.3166\n",
      "Epoch 28/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3537 - acc: 0.3211 - val_loss: 1.3578 - val_acc: 0.3248\n",
      "Epoch 29/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3537 - acc: 0.3190 - val_loss: 1.3545 - val_acc: 0.3197\n",
      "Epoch 30/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3537 - acc: 0.3207 - val_loss: 1.3602 - val_acc: 0.3125\n",
      "Epoch 31/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3530 - acc: 0.3201 - val_loss: 1.3595 - val_acc: 0.3132\n",
      "Epoch 32/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3523 - acc: 0.3222 - val_loss: 1.3582 - val_acc: 0.3248\n",
      "Epoch 33/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3525 - acc: 0.3222 - val_loss: 1.3554 - val_acc: 0.3296\n",
      "Epoch 34/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3513 - acc: 0.3243 - val_loss: 1.3585 - val_acc: 0.3223\n",
      "Epoch 35/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3515 - acc: 0.3214 - val_loss: 1.3599 - val_acc: 0.3232\n",
      "Epoch 36/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3517 - acc: 0.3206 - val_loss: 1.3564 - val_acc: 0.3201\n",
      "Epoch 37/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3509 - acc: 0.3234 - val_loss: 1.3582 - val_acc: 0.3164\n",
      "Epoch 38/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3511 - acc: 0.3228 - val_loss: 1.3543 - val_acc: 0.3228\n",
      "Epoch 39/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3507 - acc: 0.3234 - val_loss: 1.3568 - val_acc: 0.3231\n",
      "Epoch 40/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3503 - acc: 0.3262 - val_loss: 1.3562 - val_acc: 0.3269\n",
      "Epoch 41/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3500 - acc: 0.3243 - val_loss: 1.3532 - val_acc: 0.3322\n",
      "Epoch 42/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3493 - acc: 0.3243 - val_loss: 1.3559 - val_acc: 0.3245\n",
      "Epoch 43/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3496 - acc: 0.3226 - val_loss: 1.3539 - val_acc: 0.3304\n",
      "Epoch 44/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3495 - acc: 0.3259 - val_loss: 1.3550 - val_acc: 0.3247\n",
      "Epoch 45/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3492 - acc: 0.3272 - val_loss: 1.3614 - val_acc: 0.3264\n",
      "Epoch 46/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3484 - acc: 0.3312 - val_loss: 1.3550 - val_acc: 0.3317\n",
      "Epoch 47/100\n",
      "30589/30589 [==============================] - 0s 13us/step - loss: 1.3484 - acc: 0.3254 - val_loss: 1.3558 - val_acc: 0.3245\n",
      "Epoch 48/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3483 - acc: 0.3261 - val_loss: 1.3543 - val_acc: 0.3200\n",
      "Epoch 49/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3474 - acc: 0.3292 - val_loss: 1.3555 - val_acc: 0.3341\n",
      "Epoch 50/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3477 - acc: 0.3288 - val_loss: 1.3551 - val_acc: 0.3315\n",
      "Epoch 51/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3475 - acc: 0.3286 - val_loss: 1.3582 - val_acc: 0.3184\n",
      "Epoch 52/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3473 - acc: 0.3275 - val_loss: 1.3570 - val_acc: 0.3210\n",
      "Epoch 53/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3464 - acc: 0.3313 - val_loss: 1.3531 - val_acc: 0.3308\n",
      "Epoch 54/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3471 - acc: 0.3296 - val_loss: 1.3542 - val_acc: 0.3303\n",
      "Epoch 55/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3457 - acc: 0.3302 - val_loss: 1.3558 - val_acc: 0.3258\n",
      "Epoch 56/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3459 - acc: 0.3287 - val_loss: 1.3609 - val_acc: 0.3282\n",
      "Epoch 57/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3463 - acc: 0.3288 - val_loss: 1.3533 - val_acc: 0.3291\n",
      "Epoch 58/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3455 - acc: 0.3299 - val_loss: 1.3546 - val_acc: 0.3322\n",
      "Epoch 59/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3456 - acc: 0.3313 - val_loss: 1.3548 - val_acc: 0.3162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3451 - acc: 0.3284 - val_loss: 1.3569 - val_acc: 0.3333\n",
      "Epoch 61/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3451 - acc: 0.3287 - val_loss: 1.3549 - val_acc: 0.3228\n",
      "Epoch 62/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3449 - acc: 0.3341 - val_loss: 1.3592 - val_acc: 0.3141\n",
      "Epoch 63/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3447 - acc: 0.3305 - val_loss: 1.3563 - val_acc: 0.3311\n",
      "Epoch 64/100\n",
      "30589/30589 [==============================] - 0s 13us/step - loss: 1.3442 - acc: 0.3332 - val_loss: 1.3611 - val_acc: 0.3313\n",
      "Epoch 65/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3445 - acc: 0.3308 - val_loss: 1.3579 - val_acc: 0.3260\n",
      "Epoch 66/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3436 - acc: 0.3327 - val_loss: 1.3570 - val_acc: 0.3273\n",
      "Epoch 67/100\n",
      "30589/30589 [==============================] - 0s 14us/step - loss: 1.3439 - acc: 0.3309 - val_loss: 1.3558 - val_acc: 0.3254\n",
      "Epoch 68/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3437 - acc: 0.3320 - val_loss: 1.3572 - val_acc: 0.3298\n",
      "Epoch 69/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3432 - acc: 0.3319 - val_loss: 1.3595 - val_acc: 0.3258\n",
      "Epoch 70/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3430 - acc: 0.3319 - val_loss: 1.3588 - val_acc: 0.3248\n",
      "Epoch 71/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3429 - acc: 0.3315 - val_loss: 1.3597 - val_acc: 0.3291\n",
      "Epoch 72/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3429 - acc: 0.3322 - val_loss: 1.3555 - val_acc: 0.3320\n",
      "Epoch 73/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3427 - acc: 0.3311 - val_loss: 1.3570 - val_acc: 0.3305\n",
      "Epoch 74/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3423 - acc: 0.3354 - val_loss: 1.3566 - val_acc: 0.3300\n",
      "Epoch 75/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3422 - acc: 0.3362 - val_loss: 1.3597 - val_acc: 0.3251\n",
      "Epoch 76/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3418 - acc: 0.3343 - val_loss: 1.3583 - val_acc: 0.3190\n",
      "Epoch 77/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3418 - acc: 0.3370 - val_loss: 1.3611 - val_acc: 0.3219\n",
      "Epoch 78/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3418 - acc: 0.3354 - val_loss: 1.3571 - val_acc: 0.3222\n",
      "Epoch 79/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3415 - acc: 0.3350 - val_loss: 1.3610 - val_acc: 0.3317\n",
      "Epoch 80/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3416 - acc: 0.3380 - val_loss: 1.3574 - val_acc: 0.3285\n",
      "Epoch 81/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3414 - acc: 0.3360 - val_loss: 1.3570 - val_acc: 0.3269\n",
      "Epoch 82/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3414 - acc: 0.3355 - val_loss: 1.3558 - val_acc: 0.3358\n",
      "Epoch 83/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3406 - acc: 0.3370 - val_loss: 1.3602 - val_acc: 0.3279\n",
      "Epoch 84/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3402 - acc: 0.3374 - val_loss: 1.3599 - val_acc: 0.3279\n",
      "Epoch 85/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3408 - acc: 0.3386 - val_loss: 1.3574 - val_acc: 0.3368\n",
      "Epoch 86/100\n",
      "30589/30589 [==============================] - 0s 12us/step - loss: 1.3404 - acc: 0.3370 - val_loss: 1.3569 - val_acc: 0.3326\n",
      "Epoch 87/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3405 - acc: 0.3373 - val_loss: 1.3606 - val_acc: 0.3370\n",
      "Epoch 88/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3397 - acc: 0.3371 - val_loss: 1.3645 - val_acc: 0.3283\n",
      "Epoch 89/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3402 - acc: 0.3364 - val_loss: 1.3607 - val_acc: 0.3332\n",
      "Epoch 90/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3402 - acc: 0.3355 - val_loss: 1.3577 - val_acc: 0.3319\n",
      "Epoch 91/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3398 - acc: 0.3398 - val_loss: 1.3619 - val_acc: 0.3249\n",
      "Epoch 92/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3398 - acc: 0.3380 - val_loss: 1.3587 - val_acc: 0.3313\n",
      "Epoch 93/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3387 - acc: 0.3388 - val_loss: 1.3584 - val_acc: 0.3243\n",
      "Epoch 94/100\n",
      "30589/30589 [==============================] - 0s 11us/step - loss: 1.3396 - acc: 0.3404 - val_loss: 1.3573 - val_acc: 0.3328\n",
      "Epoch 95/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3390 - acc: 0.3417 - val_loss: 1.3591 - val_acc: 0.3337\n",
      "Epoch 96/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3389 - acc: 0.3369 - val_loss: 1.3614 - val_acc: 0.3300\n",
      "Epoch 97/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3389 - acc: 0.3396 - val_loss: 1.3601 - val_acc: 0.3338\n",
      "Epoch 98/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3384 - acc: 0.3390 - val_loss: 1.3590 - val_acc: 0.3282\n",
      "Epoch 99/100\n",
      "30589/30589 [==============================] - 0s 10us/step - loss: 1.3384 - acc: 0.3417 - val_loss: 1.3592 - val_acc: 0.3338\n",
      "Epoch 100/100\n",
      "30589/30589 [==============================] - 0s 9us/step - loss: 1.3385 - acc: 0.3401 - val_loss: 1.3593 - val_acc: 0.3247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129ce07f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=128, validation_data=(X_test, Y_test), shuffle=True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7648/7648 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3581676882181208, 0.31982217573221755]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test, y=Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=50, input_length=10))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, input_shape=X_train[0].shape, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30589 samples, validate on 7648 samples\n",
      "Epoch 1/100\n",
      "30589/30589 [==============================] - 1s 24us/step - loss: 1.3595 - acc: 0.3101 - val_loss: 1.3461 - val_acc: 0.3334\n",
      "Epoch 2/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.3509 - acc: 0.3262 - val_loss: 1.3441 - val_acc: 0.3313\n",
      "Epoch 3/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.3477 - acc: 0.3328 - val_loss: 1.3403 - val_acc: 0.3398\n",
      "Epoch 4/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.3447 - acc: 0.3359 - val_loss: 1.3421 - val_acc: 0.3435\n",
      "Epoch 5/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.3418 - acc: 0.3370 - val_loss: 1.3391 - val_acc: 0.3418\n",
      "Epoch 6/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.3391 - acc: 0.3426 - val_loss: 1.3383 - val_acc: 0.3405\n",
      "Epoch 7/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3364 - acc: 0.3443 - val_loss: 1.3386 - val_acc: 0.3428\n",
      "Epoch 8/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3339 - acc: 0.3437 - val_loss: 1.3389 - val_acc: 0.3426\n",
      "Epoch 9/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.3307 - acc: 0.3459 - val_loss: 1.3403 - val_acc: 0.3424\n",
      "Epoch 10/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3278 - acc: 0.3479 - val_loss: 1.3415 - val_acc: 0.3415\n",
      "Epoch 11/100\n",
      "30589/30589 [==============================] - 1s 28us/step - loss: 1.3256 - acc: 0.3484 - val_loss: 1.3428 - val_acc: 0.3407\n",
      "Epoch 12/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3227 - acc: 0.3526 - val_loss: 1.3444 - val_acc: 0.3427\n",
      "Epoch 13/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.3202 - acc: 0.3552 - val_loss: 1.3455 - val_acc: 0.3431\n",
      "Epoch 14/100\n",
      "30589/30589 [==============================] - 1s 22us/step - loss: 1.3169 - acc: 0.3544 - val_loss: 1.3421 - val_acc: 0.3444\n",
      "Epoch 15/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.3145 - acc: 0.3593 - val_loss: 1.3460 - val_acc: 0.3398\n",
      "Epoch 16/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.3113 - acc: 0.3612 - val_loss: 1.3481 - val_acc: 0.3440\n",
      "Epoch 17/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3091 - acc: 0.3591 - val_loss: 1.3497 - val_acc: 0.3398\n",
      "Epoch 18/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3064 - acc: 0.3645 - val_loss: 1.3531 - val_acc: 0.3371\n",
      "Epoch 19/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3044 - acc: 0.3657 - val_loss: 1.3531 - val_acc: 0.3430\n",
      "Epoch 20/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.3014 - acc: 0.3671 - val_loss: 1.3573 - val_acc: 0.3434\n",
      "Epoch 21/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2989 - acc: 0.3694 - val_loss: 1.3554 - val_acc: 0.3423\n",
      "Epoch 22/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2961 - acc: 0.3724 - val_loss: 1.3611 - val_acc: 0.3393\n",
      "Epoch 23/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2934 - acc: 0.3707 - val_loss: 1.3614 - val_acc: 0.3367\n",
      "Epoch 24/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2912 - acc: 0.3727 - val_loss: 1.3657 - val_acc: 0.3370\n",
      "Epoch 25/100\n",
      "30589/30589 [==============================] - 1s 21us/step - loss: 1.2890 - acc: 0.3744 - val_loss: 1.3678 - val_acc: 0.3428\n",
      "Epoch 26/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2866 - acc: 0.3741 - val_loss: 1.3674 - val_acc: 0.3367\n",
      "Epoch 27/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2853 - acc: 0.3752 - val_loss: 1.3764 - val_acc: 0.3338\n",
      "Epoch 28/100\n",
      "30589/30589 [==============================] - 1s 21us/step - loss: 1.2829 - acc: 0.3761 - val_loss: 1.3721 - val_acc: 0.3363\n",
      "Epoch 29/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2801 - acc: 0.3794 - val_loss: 1.3786 - val_acc: 0.3452\n",
      "Epoch 30/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2788 - acc: 0.3802 - val_loss: 1.3760 - val_acc: 0.3322\n",
      "Epoch 31/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2761 - acc: 0.3805 - val_loss: 1.3850 - val_acc: 0.3401\n",
      "Epoch 32/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2747 - acc: 0.3797 - val_loss: 1.3800 - val_acc: 0.3409\n",
      "Epoch 33/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2730 - acc: 0.3841 - val_loss: 1.3891 - val_acc: 0.3388\n",
      "Epoch 34/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2711 - acc: 0.3829 - val_loss: 1.3899 - val_acc: 0.3388\n",
      "Epoch 35/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2696 - acc: 0.3856 - val_loss: 1.3924 - val_acc: 0.3321\n",
      "Epoch 36/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2675 - acc: 0.3851 - val_loss: 1.4001 - val_acc: 0.3411\n",
      "Epoch 37/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2663 - acc: 0.3859 - val_loss: 1.3959 - val_acc: 0.3389\n",
      "Epoch 38/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2645 - acc: 0.3867 - val_loss: 1.3976 - val_acc: 0.3434\n",
      "Epoch 39/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2626 - acc: 0.3873 - val_loss: 1.4044 - val_acc: 0.3389\n",
      "Epoch 40/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2618 - acc: 0.3838 - val_loss: 1.4050 - val_acc: 0.3414\n",
      "Epoch 41/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2598 - acc: 0.3882 - val_loss: 1.4154 - val_acc: 0.3389\n",
      "Epoch 42/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2584 - acc: 0.3889 - val_loss: 1.4134 - val_acc: 0.3443\n",
      "Epoch 43/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2563 - acc: 0.3923 - val_loss: 1.4176 - val_acc: 0.3383\n",
      "Epoch 44/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2559 - acc: 0.3894 - val_loss: 1.4181 - val_acc: 0.3392\n",
      "Epoch 45/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2545 - acc: 0.3879 - val_loss: 1.4127 - val_acc: 0.3407\n",
      "Epoch 46/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2527 - acc: 0.3925 - val_loss: 1.4213 - val_acc: 0.3410\n",
      "Epoch 47/100\n",
      "30589/30589 [==============================] - 1s 23us/step - loss: 1.2522 - acc: 0.3918 - val_loss: 1.4326 - val_acc: 0.3333\n",
      "Epoch 48/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2514 - acc: 0.3907 - val_loss: 1.4332 - val_acc: 0.3426\n",
      "Epoch 49/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2492 - acc: 0.3939 - val_loss: 1.4316 - val_acc: 0.3432\n",
      "Epoch 50/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2486 - acc: 0.3923 - val_loss: 1.4320 - val_acc: 0.3356\n",
      "Epoch 51/100\n",
      "30589/30589 [==============================] - 1s 21us/step - loss: 1.2469 - acc: 0.3935 - val_loss: 1.4350 - val_acc: 0.3364\n",
      "Epoch 52/100\n",
      "30589/30589 [==============================] - 1s 21us/step - loss: 1.2472 - acc: 0.3915 - val_loss: 1.4380 - val_acc: 0.3358\n",
      "Epoch 53/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2456 - acc: 0.3931 - val_loss: 1.4449 - val_acc: 0.3379\n",
      "Epoch 54/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2442 - acc: 0.3943 - val_loss: 1.4402 - val_acc: 0.3350\n",
      "Epoch 55/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2440 - acc: 0.3946 - val_loss: 1.4530 - val_acc: 0.3406\n",
      "Epoch 56/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2424 - acc: 0.3957 - val_loss: 1.4565 - val_acc: 0.3397\n",
      "Epoch 57/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2424 - acc: 0.3943 - val_loss: 1.4411 - val_acc: 0.3413\n",
      "Epoch 58/100\n",
      "30589/30589 [==============================] - 1s 23us/step - loss: 1.2412 - acc: 0.3967 - val_loss: 1.4655 - val_acc: 0.3390\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2398 - acc: 0.3972 - val_loss: 1.4642 - val_acc: 0.3411\n",
      "Epoch 60/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2397 - acc: 0.3969 - val_loss: 1.4545 - val_acc: 0.3406\n",
      "Epoch 61/100\n",
      "30589/30589 [==============================] - 1s 23us/step - loss: 1.2380 - acc: 0.3969 - val_loss: 1.4704 - val_acc: 0.3363\n",
      "Epoch 62/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2387 - acc: 0.3955 - val_loss: 1.4690 - val_acc: 0.3409\n",
      "Epoch 63/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2374 - acc: 0.3980 - val_loss: 1.4644 - val_acc: 0.3336\n",
      "Epoch 64/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2372 - acc: 0.3973 - val_loss: 1.4641 - val_acc: 0.3362\n",
      "Epoch 65/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2366 - acc: 0.3957 - val_loss: 1.4791 - val_acc: 0.3342\n",
      "Epoch 66/100\n",
      "30589/30589 [==============================] - 1s 23us/step - loss: 1.2353 - acc: 0.3982 - val_loss: 1.4738 - val_acc: 0.3339\n",
      "Epoch 67/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2350 - acc: 0.3979 - val_loss: 1.4686 - val_acc: 0.3355\n",
      "Epoch 68/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2350 - acc: 0.3968 - val_loss: 1.4887 - val_acc: 0.3368\n",
      "Epoch 69/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2343 - acc: 0.3981 - val_loss: 1.4698 - val_acc: 0.3356\n",
      "Epoch 70/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2341 - acc: 0.3995 - val_loss: 1.4783 - val_acc: 0.3347\n",
      "Epoch 71/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2342 - acc: 0.3959 - val_loss: 1.4784 - val_acc: 0.3349\n",
      "Epoch 72/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2330 - acc: 0.4003 - val_loss: 1.4917 - val_acc: 0.3342\n",
      "Epoch 73/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2330 - acc: 0.3965 - val_loss: 1.4864 - val_acc: 0.3401\n",
      "Epoch 74/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2322 - acc: 0.4001 - val_loss: 1.4853 - val_acc: 0.3384\n",
      "Epoch 75/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2320 - acc: 0.3969 - val_loss: 1.4855 - val_acc: 0.3347\n",
      "Epoch 76/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2312 - acc: 0.4013 - val_loss: 1.4796 - val_acc: 0.3380\n",
      "Epoch 77/100\n",
      "30589/30589 [==============================] - 1s 17us/step - loss: 1.2311 - acc: 0.3995 - val_loss: 1.4904 - val_acc: 0.3385\n",
      "Epoch 78/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2304 - acc: 0.3981 - val_loss: 1.5070 - val_acc: 0.3356\n",
      "Epoch 79/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2309 - acc: 0.3987 - val_loss: 1.4902 - val_acc: 0.3452\n",
      "Epoch 80/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2295 - acc: 0.3995 - val_loss: 1.4886 - val_acc: 0.3353\n",
      "Epoch 81/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2294 - acc: 0.4013 - val_loss: 1.5017 - val_acc: 0.3389\n",
      "Epoch 82/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2296 - acc: 0.4016 - val_loss: 1.5087 - val_acc: 0.3384\n",
      "Epoch 83/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2283 - acc: 0.4003 - val_loss: 1.5007 - val_acc: 0.3394\n",
      "Epoch 84/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2290 - acc: 0.3990 - val_loss: 1.5036 - val_acc: 0.3385\n",
      "Epoch 85/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2282 - acc: 0.4007 - val_loss: 1.5069 - val_acc: 0.3390\n",
      "Epoch 86/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2274 - acc: 0.4009 - val_loss: 1.5052 - val_acc: 0.3404\n",
      "Epoch 87/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2290 - acc: 0.3981 - val_loss: 1.5136 - val_acc: 0.3411\n",
      "Epoch 88/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2281 - acc: 0.4029 - val_loss: 1.5063 - val_acc: 0.3392\n",
      "Epoch 89/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2272 - acc: 0.3981 - val_loss: 1.5014 - val_acc: 0.3385A: 0s - loss: 1.2235 - acc: 0.\n",
      "Epoch 90/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2267 - acc: 0.4019 - val_loss: 1.5077 - val_acc: 0.3409\n",
      "Epoch 91/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2269 - acc: 0.4001 - val_loss: 1.4924 - val_acc: 0.3337\n",
      "Epoch 92/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2269 - acc: 0.4000 - val_loss: 1.5134 - val_acc: 0.3387\n",
      "Epoch 93/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2261 - acc: 0.4012 - val_loss: 1.4992 - val_acc: 0.3346\n",
      "Epoch 94/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2268 - acc: 0.4044 - val_loss: 1.5167 - val_acc: 0.3359\n",
      "Epoch 95/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2258 - acc: 0.4001 - val_loss: 1.5166 - val_acc: 0.3321\n",
      "Epoch 96/100\n",
      "30589/30589 [==============================] - 1s 19us/step - loss: 1.2265 - acc: 0.4004 - val_loss: 1.5143 - val_acc: 0.3376\n",
      "Epoch 97/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2263 - acc: 0.4024 - val_loss: 1.5207 - val_acc: 0.3389\n",
      "Epoch 98/100\n",
      "30589/30589 [==============================] - 1s 20us/step - loss: 1.2262 - acc: 0.3997 - val_loss: 1.5167 - val_acc: 0.3338\n",
      "Epoch 99/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2247 - acc: 0.4002 - val_loss: 1.5225 - val_acc: 0.3387\n",
      "Epoch 100/100\n",
      "30589/30589 [==============================] - 1s 18us/step - loss: 1.2254 - acc: 0.4004 - val_loss: 1.5387 - val_acc: 0.3394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1281c2c50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=128, validation_data=(X_test, Y_test), shuffle=True, callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7648/7648 [==============================] - 0s 34us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3543388035506883, 0.33734309623430964]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test, y=Y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'baby', 'how', 'you', 'doing', 'you', 'know', 'im', 'gonna', 'cut']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
