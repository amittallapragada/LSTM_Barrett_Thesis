{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis Demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KnQ4cm9G7kmu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Barrett Thesis Demo: Generating and Classifying Lyrics with LSTM Networks"
      ]
    },
    {
      "metadata": {
        "id": "4ZZ6CDviOFRL",
        "colab_type": "code",
        "outputId": "1ea08848-e109-42c6-f409-f80d4672fda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "import pickle\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1x0UEdzJOLsY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generator Demo"
      ]
    },
    {
      "metadata": {
        "id": "RI73EAp3ONu-",
        "colab_type": "code",
        "outputId": "5e41c807-ce87-4628-ab97-0a07e91b0a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "cell_type": "code",
      "source": [
        "with open('drive/My Drive/Colab Notebooks/data/t_swift_model_architecture.json', 'r') as f:\n",
        "    model = model_from_json(f.read())\n",
        "\n",
        "model.load_weights('drive/My Drive/Colab Notebooks/data/final_tswift_model_weights.h5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 24, 50)            122300    \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               92160     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2446)              315534    \n",
            "=================================================================\n",
            "Total params: 529,994\n",
            "Trainable params: 529,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Ix3qkPOPDkc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generator Function"
      ]
    },
    {
      "metadata": {
        "id": "2ggZihZuOZcq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('drive/My Drive/Colab Notebooks/data/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "max_len = 25\n",
        "ind_to_word = dict((v,k) for k,v in tokenizer.word_index.items())\n",
        "\n",
        "\n",
        "def generate_text(seed_text, num_of_words_to_gen):\n",
        "\n",
        "    for j in range(num_of_words_to_gen):\n",
        "        #format token as a model input\n",
        "        seed_token = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        seed_token = pad_sequences([seed_token], maxlen=max_len-1, padding='pre')\n",
        "        #predict\n",
        "        predicted = model.predict_classes(seed_token, verbose=0)\n",
        "        output_word = ind_to_word[predicted[0]]\n",
        "\n",
        "        seed_text = seed_text + \" \" + output_word\n",
        "        if j % 10 == 0 and j != 0:\n",
        "          seed_text = seed_text + \"\\n\"\n",
        "    print('\\n')\n",
        "    return seed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaagNjcDO_hg",
        "colab_type": "code",
        "outputId": "f780e509-e843-4b99-d29f-a7c5f0b4b383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "temp = generate_text('arizona star', 100)\n",
        "print(temp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "arizona star i was enchanted to meet you when i was drowning you're\n",
            " still in his pocket open open for the door for\n",
            " you come right on us life ain't like a little\n",
            " same times if i had known now i don't know\n",
            " what you would be little mind caught up like this\n",
            " time why you are you gave we in the very\n",
            " first fight\r were ready dreaming of me this alright mad\n",
            " eye year pretty every life waiting plaid alright hunters least\n",
            " thought you pushed like small did could be mad love\n",
            " me this mad mad mad this mad strange onto\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0vWcvZhhQZRc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "xj82vjHpQah6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifier **Demo**"
      ]
    },
    {
      "metadata": {
        "id": "kBShprUkPK77",
        "colab_type": "code",
        "outputId": "f43466cd-0f0b-41ac-e747-a52bdebb95f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "cell_type": "code",
      "source": [
        "with open('drive/My Drive/Colab Notebooks/data/classifier_model_architecture.json', 'r') as f:\n",
        "  c_model = model_from_json(f.read())\n",
        "\n",
        "c_model.load_weights('drive/My Drive/Colab Notebooks/data/final_classifier_model_weights.h5')\n",
        "\n",
        "\n",
        "with open('drive/My Drive/Colab Notebooks/data//classifier_tokenizer.pickle', 'rb') as handle:\n",
        "    tok = pickle.load(handle)\n",
        "  \n",
        "  \n",
        "  \n",
        "one_hot = {'Pop':[1,0,0,0], 'Hip-Hop':[0,1,0,0], 'Metal': [0,0,1,0], 'Rock':[0,0,0,1]}\n",
        "\n",
        "c_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm_4 (CuDNNLSTM)     (None, 128)               67072     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 516       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 67,588\n",
            "Trainable params: 67,588\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zj1KY-DLWLCj",
        "colab_type": "code",
        "outputId": "254df8c3-a921-4cd8-ab4f-f1d1a2944495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "song = input()\n",
        "\n",
        "song = song.lower()\n",
        "song = song.replace('\\n', ' ')\n",
        "song = song.split(' ')\n",
        "song = [song]\n",
        "\n",
        "#break into seqs\n",
        "sequences = tok.texts_to_sequences(song)\n",
        "sequences_matrix = sequence.pad_sequences(sequences, maxlen=8196)\n",
        "sequences_matrix = sequences_matrix.reshape(1, 8196, 1)\n",
        "\n",
        "#predict\n",
        "output = c_model.predict(sequences_matrix)\n",
        "print(output)\n",
        "#jank solution to output genre name\n",
        "song = [0,0,0,0]\n",
        "max_val = np.argmax(output)\n",
        "song[max_val] = 1\n",
        "for k,v in one_hot.items():\n",
        "  if song == v:\n",
        "    print(k)\n",
        "    break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thought I'd end up with Sean But he wasn't a match Wrote some songs about Ricky Now I listen and laugh Even almost got married And for Pete, I'm so thankful Wish I could say, \"Thank you\" to Malcolm 'Cause he was an angel One taught me love One taught me patience And one taught me pain Now, I'm so amazing I've loved and I've lost But that's not what I see So, look what I got Look what you taught me And for that, I say Thank you, next (next) Thank you, next (next) Thank you, next I'm so fuckin' grateful for my ex Thank you, next (next) Thank you, next (next) Thank you, next (next) I'm so fuckin' Spend more time with my friends I ain't worried 'bout nothin' Plus, I met someone else We havin' better discussions I know they say I move on too fast But this one gon' last 'Cause her name is Ari And I'm so good with that (so good with that) She taught me love (love) She taught me patience (patience) How she handles pain (pain) That shit's amazing (yeah, she's amazing) I've loved and I've lost (yeah, yeah) But that's not what I see (yeah, yeah) 'Cause look what I've found (yeah, yeah) Ain't no need for searching, and for that, I say Thank you, next (thank you, next) Thank you, next (thank you, next) Thank you, next (thank you) I'm so fuckin' grateful for my ex Thank you, next (thank you, next) Thank you, next (said thank you, next) Thank you, next (next) I'm so fuckin' grateful for my ex Thank you, next Thank you, next Thank you, next I'm so fucking One day I'll walk down the aisle Holding hands with my mama I'll be thanking my dad 'Cause she grew from the drama Only wanna do it once, real bad Gon' make that shit last God forbid something happens Least this song is a smash (song is a smash) I've got so much love (love) Got so much patience (patience) I've learned from the pain (pain) I turned out amazing (turned out amazing) I've loved and I've lost (yeah, yeah) But that's not what I see (yeah, yeah) 'Cause look what I've found (yeah, yeah) Ain't no need for searching And for that, I'll say Thank you, next (thank you, next) Thank you, next (thank you, next) Thank you, next I'm so fuckin' grateful for my ex Thank you, next (thank you, next) Thank you, next (said thank you, next) Thank you, next (next) I'm so fuckin' grateful for my ex Thank you, next Thank you, next Thank you, next Yeah, yee Thank you, next Thank you, next Thank you, next Yeah, yee\n",
            "[[0.37362665 0.43837988 0.01779049 0.17020291]]\n",
            "Hip-Hop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GYdDVFWOWYtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}